{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "# import model.resnet_mutilabels as models\n",
    "# from torchvision import models\n",
    "# import models\n",
    "from torchvision.models.swin_transformer import Swin_B_Weights, Swin_T_Weights, Swin_S_Weights\n",
    "from data import RoadBreak, RoadAllData\n",
    "import random\n",
    "import models\n",
    "from PIL import Image\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0303, 0.3741]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.2369, -0.1491]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((4,6))\n",
    "model1_ori = torch.nn.Sequential(\n",
    "    torch.nn.Linear(6, 2), \n",
    "    torch.nn.Linear(2, 2)\n",
    ")\n",
    "model2_ori = torch.nn.Sequential(\n",
    "    torch.nn.Linear(6, 2), \n",
    "    torch.nn.Linear(2, 2)\n",
    ")\n",
    "y = torch.rand((1,6))\n",
    "\n",
    "model1_ori(y), model2_ori(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0302, 0.3743]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.2368, -0.1490]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce = torch.nn.CrossEntropyLoss()\n",
    "target = torch.Tensor([0, 1, 1, 0]).type(torch.long)\n",
    "model1 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(6, 2), \n",
    "    torch.nn.Linear(2, 2)\n",
    ")\n",
    "model2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(6, 2), \n",
    "    torch.nn.Linear(2, 2)\n",
    ")\n",
    "for param, param_bak in zip(model1.parameters(), model1_ori.parameters()):\n",
    "    param.data = param_bak.data.clone()\n",
    "\n",
    "for param, param_bak in zip(model2.parameters(), model2_ori.parameters()):\n",
    "    param.data = param_bak.data.clone()\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=list(model1.parameters()) + list(model2.parameters()))\n",
    "score = model1(x) + model2(x)\n",
    "loss = ce(score, target)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "model1(y), model2(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0302, 0.3743]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.2368, -0.1490]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce = torch.nn.CrossEntropyLoss()\n",
    "target = torch.Tensor([0, 1, 1, 0]).type(torch.long)\n",
    "model1 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(6, 2), \n",
    "    torch.nn.Linear(2, 2)\n",
    ")\n",
    "model2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(6, 2), \n",
    "    torch.nn.Linear(2, 2)\n",
    ")\n",
    "for param, param_bak in zip(model1.parameters(), model1_ori.parameters()):\n",
    "    param.data = param_bak.data.clone()\n",
    "\n",
    "for param, param_bak in zip(model2.parameters(), model2_ori.parameters()):\n",
    "    param.data = param_bak.data.clone()\n",
    "optimizer1 = torch.optim.Adam(lr=1e-4, params=model1.parameters())\n",
    "optimizer2 = torch.optim.Adam(lr=1e-4, params=model2.parameters())\n",
    "score = model1(x) + model2(x)\n",
    "loss = ce(score, target)\n",
    "optimizer1.zero_grad()\n",
    "optimizer2.zero_grad()\n",
    "loss.backward()\n",
    "optimizer1.step()\n",
    "optimizer2.step()\n",
    "model1(y), model2(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mean = np.load('data/hist_mean.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_std = np.load('data/hist_std.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2236"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hist_std == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2236)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((2, 4096))\n",
    "a[:, hist_mean==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = np.zeros((0, 3)).astype('uint8')\n",
    "for i in range(29100, 29160):\n",
    "    print(i)\n",
    "    img = cv2.imread(r'/data2/zrliu/dataset_cmp/dataset/train_image/labeled_data/train_{}.png'.format(i))\n",
    "    unique = np.unique(np.concatenate([unique, np.unique(img.reshape(-1, 3), axis=0)]), axis=0)\n",
    "print(len(unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'/data2/zrliu/dataset_cmp/dataset/train_image/labeled_data/train_29100.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Histogram(torch.nn.Module):\n",
    "    def __init__(self, levels=16):\n",
    "        self.levels = levels\n",
    "        self.max_v = levels ** 3\n",
    "        self.v_num = (256 // levels)\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        img = img // self.v_num\n",
    "        img = img.astype(int)\n",
    "        values = img[:, :, 2] * (self.levels * self.levels)\n",
    "        values += img[:, :, 1] * self.levels\n",
    "        values += img[:, :, 0]\n",
    "        values = values.reshape(-1)\n",
    "        values = np.insert(values, len(values), self.max_v)\n",
    "        return np.bincount(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = Histogram(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29164\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n"
     ]
    }
   ],
   "source": [
    "data_path = '/data2/zrliu/dataset_cmp/dataset/train_image/labeled_data'\n",
    "hists = []\n",
    "print(len(os.listdir(data_path)))\n",
    "for i, name in enumerate(os.listdir(data_path)):\n",
    "    img = Image.open(os.path.join(data_path, name)).convert('RGB')\n",
    "    img = np.array(img)\n",
    "    \n",
    "    hists.append(hist(img))\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "        \n",
    "        \n",
    "hists = np.array(hists)\n",
    "mean = hists.mean(axis=0)\n",
    "std = hists.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53155,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std[std>0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53156,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean[mean>0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/zrliu/repo_semi_supervised/hist_mean_64.npy', mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/zrliu/repo_semi_supervised/debug.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7/home/zrliu/repo_semi_supervised/debug.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m mean[\u001b[39m0\u001b[39m\u001b[39m<\u001b[39mmean\u001b[39m<\u001b[39m\u001b[39m1000\u001b[39m]\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "mean[mean>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/zrliu/repo_semi_supervised/hist_std_64.npy', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2236"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(std[std == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29164, 4096)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 3), dtype=float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabnanny import check\n",
    "\n",
    "\n",
    "model = models.__dict__['resnet34']()\n",
    "checkpoint = torch.load('/data2/zrliu/checkpoints/hwcmp/checkpoint_0009.pth.tar')\n",
    "state_dict = checkpoint['state_dict']\n",
    "for k in list(state_dict.keys()):\n",
    "    # retain only encoder_q up to before the embedding layer\n",
    "    if k.startswith('module.encoder_q') and not k.startswith('module.encoder_q.fc'):\n",
    "        # remove prefix\n",
    "        state_dict[k[len(\"module.encoder_q.\"):]] = state_dict[k]\n",
    "    # delete renamed or unused k\n",
    "    del state_dict[k]\n",
    "msg = model.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['fc.0.weight', 'fc.0.bias', 'fc.1.weight', 'fc.1.bias', 'fc.2.weight', 'fc.2.bias', 'fc.3.weight', 'fc.3.bias', 'fc.4.weight', 'fc.4.bias', 'fc.5.weight', 'fc.5.bias', 'fc.6.weight', 'fc.6.bias', 'fc.7.weight', 'fc.7.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RoadAllData.__init__() got an unexpected keyword argument 'rate_for_crop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/zrliu/repo_semi_supervised/debug.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7/home/zrliu/repo_semi_supervised/debug.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m dataset \u001b[39m=\u001b[39m RoadAllData(\u001b[39m'\u001b[39;49m\u001b[39m/data2/zrliu/dataset_cmp/dataset/\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m, rate_for_crop\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, rand_filp\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, to\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mndarray\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: RoadAllData.__init__() got an unexpected keyword argument 'rate_for_crop'"
     ]
    }
   ],
   "source": [
    "dataset = RoadAllData('/data2/zrliu/dataset_cmp/dataset', transform=None, mode='train', expand=False, split=args.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty range for randrange() (0, 0, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/zrliu/repo_semi_supervised/debug.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7/home/zrliu/repo_semi_supervised/debug.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m img \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m3\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m255\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7/home/zrliu/repo_semi_supervised/debug.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m rb \u001b[39m=\u001b[39m RoadBreak()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7/home/zrliu/repo_semi_supervised/debug.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m rb(img)\n",
      "File \u001b[0;32m~/repo_semi_supervised/data/mytransforms.py:571\u001b[0m, in \u001b[0;36mRoadBreak.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    569\u001b[0m index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnonzero(res)  \u001b[39m# 返回索引\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[39mfor\u001b[39;00m attempt \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m--> 571\u001b[0m     choice \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39;49mrandint(\u001b[39m0\u001b[39;49m, \u001b[39mlen\u001b[39;49m(index[\u001b[39m0\u001b[39;49m]) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    572\u001b[0m     \u001b[39m# print(choice)\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     position \u001b[39m=\u001b[39m [index[\u001b[39m0\u001b[39m][choice], index[\u001b[39m1\u001b[39m][choice]]\n",
      "File \u001b[0;32m~/anaconda3/envs/omnivore/lib/python3.10/random.py:370\u001b[0m, in \u001b[0;36mRandom.randint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandint\u001b[39m(\u001b[39mself\u001b[39m, a, b):\n\u001b[1;32m    367\u001b[0m     \u001b[39m\"\"\"Return random integer in range [a, b], including both end points.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandrange(a, b\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/omnivore/lib/python3.10/random.py:353\u001b[0m, in \u001b[0;36mRandom.randrange\u001b[0;34m(self, start, stop, step)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[39mif\u001b[39;00m width \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    352\u001b[0m         \u001b[39mreturn\u001b[39;00m istart \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_randbelow(width)\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mempty range for randrange() (\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (istart, istop, width))\n\u001b[1;32m    355\u001b[0m \u001b[39m# Non-unit step argument supplied.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m istep \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: empty range for randrange() (0, 0, 0)"
     ]
    }
   ],
   "source": [
    "img = (np.random.rand(224, 224, 3) * 255).astype('uint8')\n",
    "rb = RoadBreak()\n",
    "rb(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = torch.rand((1,3,468,224)).cuda()\n",
    "img2 = torch.rand((1,3,224,468)).cuda()\n",
    "label = torch.randint(0, 1000, (1,)).cuda()\n",
    "model = models.resnet34().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0005, 0.0005, 0.0005,  ..., 0.0005, 0.0005, 0.0005],\n",
       "        [0.0004, 0.0005, 0.0005,  ..., 0.0005, 0.0005, 0.0005],\n",
       "        [0.0003, 0.0003, 0.0003,  ..., 0.0003, 0.0003, 0.0003],\n",
       "        ...,\n",
       "        [0.0048, 0.0049, 0.0052,  ..., 0.0050, 0.0052, 0.0052],\n",
       "        [0.0006, 0.0006, 0.0006,  ..., 0.0006, 0.0006, 0.0006],\n",
       "        [0.0007, 0.0008, 0.0008,  ..., 0.0008, 0.0008, 0.0008]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "out1 = model(img1)\n",
    "# out2 = model(img2)\n",
    "ce = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "loss = 0\n",
    "loss += ce(out1, label)\n",
    "# loss += ce(out2, label)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "model.fc.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 512]), torch.Size([32, 512]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 512]), torch.Size([32, 512]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/zrliu/repo_semi_supervised/debug.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7/home/zrliu/repo_semi_supervised/debug.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7/home/zrliu/repo_semi_supervised/debug.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7/home/zrliu/repo_semi_supervised/debug.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mfc\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mgrad\n",
      "File \u001b[0;32m~/anaconda3/envs/omnivore/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/omnivore/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.__dict__['swin_b'](pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.__dict__['resnet18'](auxiliary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /home/zrliu/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dadfc70d94949069a3779c002b2c2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/zrliu/repo_semi_supervised/debug.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7/home/zrliu/repo_semi_supervised/debug.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39;49mswin_b(weights\u001b[39m=\u001b[39;49mSwin_B_Weights\u001b[39m.\u001b[39;49mIMAGENET1K_V1)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7/home/zrliu/repo_semi_supervised/debug.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mhead \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mSequential()\n",
      "File \u001b[0;32m~/anaconda3/envs/omnivore/lib/python3.10/site-packages/torchvision/models/swin_transformer.py:612\u001b[0m, in \u001b[0;36mswin_b\u001b[0;34m(weights, progress, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[39mConstructs a swin_base architecture from\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[39m`Swin Transformer: Hierarchical Vision Transformer using Shifted Windows <https://arxiv.org/pdf/2103.14030>`_.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[39m    :members:\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    610\u001b[0m weights \u001b[39m=\u001b[39m Swin_B_Weights\u001b[39m.\u001b[39mverify(weights)\n\u001b[0;32m--> 612\u001b[0m \u001b[39mreturn\u001b[39;00m _swin_transformer(\n\u001b[1;32m    613\u001b[0m     patch_size\u001b[39m=\u001b[39;49m[\u001b[39m4\u001b[39;49m, \u001b[39m4\u001b[39;49m],\n\u001b[1;32m    614\u001b[0m     embed_dim\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[1;32m    615\u001b[0m     depths\u001b[39m=\u001b[39;49m[\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m18\u001b[39;49m, \u001b[39m2\u001b[39;49m],\n\u001b[1;32m    616\u001b[0m     num_heads\u001b[39m=\u001b[39;49m[\u001b[39m4\u001b[39;49m, \u001b[39m8\u001b[39;49m, \u001b[39m16\u001b[39;49m, \u001b[39m32\u001b[39;49m],\n\u001b[1;32m    617\u001b[0m     window_size\u001b[39m=\u001b[39;49m[\u001b[39m7\u001b[39;49m, \u001b[39m7\u001b[39;49m],\n\u001b[1;32m    618\u001b[0m     stochastic_depth_prob\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m,\n\u001b[1;32m    619\u001b[0m     weights\u001b[39m=\u001b[39;49mweights,\n\u001b[1;32m    620\u001b[0m     progress\u001b[39m=\u001b[39;49mprogress,\n\u001b[1;32m    621\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    622\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/omnivore/lib/python3.10/site-packages/torchvision/models/swin_transformer.py:438\u001b[0m, in \u001b[0;36m_swin_transformer\u001b[0;34m(patch_size, embed_dim, depths, num_heads, window_size, stochastic_depth_prob, weights, progress, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m model \u001b[39m=\u001b[39m SwinTransformer(\n\u001b[1;32m    428\u001b[0m     patch_size\u001b[39m=\u001b[39mpatch_size,\n\u001b[1;32m    429\u001b[0m     embed_dim\u001b[39m=\u001b[39membed_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    435\u001b[0m )\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(weights\u001b[39m.\u001b[39;49mget_state_dict(progress\u001b[39m=\u001b[39;49mprogress))\n\u001b[1;32m    440\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/omnivore/lib/python3.10/site-packages/torchvision/models/_api.py:63\u001b[0m, in \u001b[0;36mWeightsEnum.get_state_dict\u001b[0;34m(self, progress)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_dict\u001b[39m(\u001b[39mself\u001b[39m, progress: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m load_state_dict_from_url(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl, progress\u001b[39m=\u001b[39;49mprogress)\n",
      "File \u001b[0;32m~/anaconda3/envs/omnivore/lib/python3.10/site-packages/torch/hub.py:727\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[1;32m    725\u001b[0m         r \u001b[39m=\u001b[39m HASH_REGEX\u001b[39m.\u001b[39msearch(filename)  \u001b[39m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[1;32m    726\u001b[0m         hash_prefix \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m r \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 727\u001b[0m     download_url_to_file(url, cached_file, hash_prefix, progress\u001b[39m=\u001b[39;49mprogress)\n\u001b[1;32m    729\u001b[0m \u001b[39mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[1;32m    730\u001b[0m     \u001b[39mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location)\n",
      "File \u001b[0;32m~/anaconda3/envs/omnivore/lib/python3.10/site-packages/torch/hub.py:615\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39mfile_size, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m progress,\n\u001b[1;32m    613\u001b[0m           unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mB\u001b[39m\u001b[39m'\u001b[39m, unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, unit_divisor\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m) \u001b[39mas\u001b[39;00m pbar:\n\u001b[1;32m    614\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 615\u001b[0m         buffer \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39;49mread(\u001b[39m8192\u001b[39;49m)\n\u001b[1;32m    616\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    617\u001b[0m             \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/omnivore/lib/python3.10/http/client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[1;32m    463\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> 465\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[1;32m    466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    467\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/anaconda3/envs/omnivore/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/omnivore/lib/python3.10/ssl.py:1273\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1270\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1271\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1272\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1273\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1275\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/omnivore/lib/python3.10/ssl.py:1129\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1128\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1129\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1130\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1131\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.swin_b(weights=Swin_B_Weights.IMAGENET1K_V1)\n",
    "model.head = torch.nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand((1,3,498,224))\n",
    "out = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('/home/zrliu/epoch_30.pkl')\n",
    "state_dict = checkpoint\n",
    "for k in list(state_dict.keys()):\n",
    "    state_dict[k[len(\"module.\"):]] = state_dict[k]\n",
    "    # delete renamed or unused k\n",
    "    del state_dict[k]\n",
    "for k in list(state_dict.keys()):\n",
    "    if k.startswith('backbone.'):\n",
    "        state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
    "        # delete renamed or unused k\n",
    "        del state_dict[k]\n",
    "\n",
    "model = models.__dict__['resnet18']()\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zrliu/anaconda3/envs/omnivore/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zrliu/anaconda3/envs/omnivore/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = basemodel.Model()\n",
    "checkpoint = torch.load('/home/zrliu/epoch_30.pkl')\n",
    "state_dict = checkpoint\n",
    "for k in list(state_dict.keys()):\n",
    "    state_dict[k[len(\"module.\"):]] = state_dict[k]\n",
    "    # delete renamed or unused k\n",
    "    del state_dict[k]\n",
    "model2.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand((1,3,224,224))\n",
    "out1, feats = model(img)\n",
    "out2 = model2(img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('backbone', ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential()\n",
      "))\n",
      "('fc', ModuleList(\n",
      "  (0): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (2): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (3): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (4): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (5): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (6): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (7): Linear(in_features=512, out_features=2, bias=True)\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "for i in model2._modules.items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.0896, -6.0345]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.0896, -6.0345]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mydataset import RoadAllData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = RoadAllData(dataset_path='/data2/zrliu/dataset_cmp/dataset', transform=None, cat='train')\n",
    "dataset_val = RoadAllData(dataset_path='/data2/zrliu/dataset_cmp/dataset', transform=None, cat='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20380, 8784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cls_dict, val_cls_dict = {}, {}\n",
    "\n",
    "for i in range(dataset_train.label_list.shape[0]):\n",
    "    cls = dataset_train.label_list[i].argmax().item()\n",
    "    if cls not in train_cls_dict:\n",
    "        train_cls_dict[cls] = 1\n",
    "    else:\n",
    "        train_cls_dict[cls] += 1\n",
    "\n",
    "for i in range(dataset_val.label_list.shape[0]):\n",
    "    cls = dataset_val.label_list[i].argmax().item()\n",
    "    if cls not in val_cls_dict:\n",
    "        val_cls_dict[cls] = 1\n",
    "    else:\n",
    "        val_cls_dict[cls] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 17981 \t 0.8823\n",
      "1 \t 142 \t 0.007\n",
      "2 \t 459 \t 0.0225\n",
      "3 \t 164 \t 0.008\n",
      "4 \t 158 \t 0.0078\n",
      "5 \t 175 \t 0.0086\n",
      "6 \t 1131 \t 0.0555\n",
      "7 \t 170 \t 0.0083\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(i, '\\t', train_cls_dict[i], '\\t', round(train_cls_dict[i] / len(dataset_train), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 25767 \t 0.8835\n",
      "1 \t 187 \t 0.0064\n",
      "2 \t 638 \t 0.0219\n",
      "3 \t 217 \t 0.0074\n",
      "4 \t 234 \t 0.008\n",
      "5 \t 255 \t 0.0087\n",
      "6 \t 1624 \t 0.0557\n",
      "7 \t 242 \t 0.0083\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(i, '\\t', train_cls_dict[i] + val_cls_dict[i], '\\t', round((train_cls_dict[i] + val_cls_dict[i]) / (len(dataset_train) + len(dataset_val)), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17981\n",
      "18002\n",
      "17212\n",
      "17968\n",
      "17583\n",
      "18092\n",
      "17819\n",
      "17868\n"
     ]
    }
   ],
   "source": [
    "data_path = '/data2/zrliu/dataset_cmp/dataset/train_label/train.csv'\n",
    "new_data_path = '/data2/zrliu/dataset_cmp/dataset/train_label/train_expand.csv'\n",
    "img_list, label_list = [], []\n",
    "repeat_count = {'0':1, '1':120, '2':28, '3':105, '4':80, '5':90, '6':8, '7':85}\n",
    "with open(data_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line_split = line.replace('\\n', '').split(',')\n",
    "        rc = 0\n",
    "        labels = []\n",
    "        for label in line_split[1:]:\n",
    "            if label != '':\n",
    "                labels.append(label)\n",
    "        for label in labels:\n",
    "            rc += repeat_count[label]\n",
    "        for i in range(rc): \n",
    "            img_list.append(line_split[0])\n",
    "            label_list.append(labels)\n",
    "\n",
    "new_count = {'0':0, '1':0, '2':0, '3':0, '4':0, '5':0, '6':0, '7':0}\n",
    "for i in range(len(img_list)):\n",
    "    for label in label_list[i]:\n",
    "        new_count[label] += 1\n",
    "\n",
    "for i in range(8):\n",
    "    print(new_count[str(i)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "csv_str = \"\"\n",
    "for i in range(len(img_list)):\n",
    "    line = [img_list[i]] + label_list[i]\n",
    "    csv_str += (','.join(line) + '\\n')\n",
    "\n",
    "with open(new_data_path, 'w') as f:\n",
    "    f.write(csv_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17981\n",
      "18002\n",
      "17212\n",
      "17968\n",
      "17583\n",
      "18092\n",
      "17819\n",
      "17868\n"
     ]
    }
   ],
   "source": [
    "new_data_path = '/data2/zrliu/dataset_cmp/dataset/train_label/train_expand.csv'\n",
    "new_count = {'0':0, '1':0, '2':0, '3':0, '4':0, '5':0, '6':0, '7':0}\n",
    "with open(new_data_path, 'r') as f:\n",
    "    for line in f:\n",
    "        split_ = line.replace('\\n', '').split(',')\n",
    "        for label in split_[1:]:\n",
    "            new_count[label] += 1\n",
    "\n",
    "for i in range(8):\n",
    "    print(new_count[str(i)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('omnivore': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f95de8dbd4be42b7193d49fb723eee718baf2da8a104cf8ddacaf377c5bf526d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
